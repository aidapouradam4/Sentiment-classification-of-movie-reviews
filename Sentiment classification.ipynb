{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24a5649",
   "metadata": {},
   "source": [
    "### Task 1 - Data Loading and data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8226c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0      1\n",
      "0     False  False\n",
      "1     False  False\n",
      "2     False  False\n",
      "3     False  False\n",
      "4     False  False\n",
      "...     ...    ...\n",
      "2395  False  False\n",
      "2396  False  False\n",
      "2397  False  False\n",
      "2398  False  False\n",
      "2399  False  False\n",
      "\n",
      "[2400 rows x 2 columns]\n",
      "          0\n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "...     ...\n",
      "2395  False\n",
      "2396  False\n",
      "2397  False\n",
      "2398  False\n",
      "2399  False\n",
      "\n",
      "[2400 rows x 1 columns]\n",
      "         0      1\n",
      "0    False  False\n",
      "1    False  False\n",
      "2    False  False\n",
      "3    False  False\n",
      "4    False  False\n",
      "..     ...    ...\n",
      "595  False  False\n",
      "596  False  False\n",
      "597  False  False\n",
      "598  False  False\n",
      "599  False  False\n",
      "\n",
      "[600 rows x 2 columns]\n",
      "         0\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "..     ...\n",
      "595  False\n",
      "596  False\n",
      "597  False\n",
      "598  False\n",
      "599  False\n",
      "\n",
      "[600 rows x 1 columns]\n",
      "(2400, 2)\n",
      "(2400, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The sweet potato fries were very good and seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>yelp</td>\n",
       "      <td>I could eat their bruschetta all day it is dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Ambience is perfect.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>yelp</td>\n",
       "      <td>We ordered the duck rare and it was pink and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Service was good and the company was better!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                  1\n",
       "0     amazon  Oh and I forgot to also mention the weird colo...\n",
       "1     amazon                       THAT one didn't work either.\n",
       "2     amazon                                 Waste of 13 bucks.\n",
       "3     amazon  Product is useless, since it does not have eno...\n",
       "4     amazon  None of the three sizes they sent with the hea...\n",
       "...      ...                                                ...\n",
       "2395    yelp  The sweet potato fries were very good and seas...\n",
       "2396    yelp  I could eat their bruschetta all day it is dev...\n",
       "2397    yelp                               Ambience is perfect.\n",
       "2398    yelp  We ordered the duck rare and it was pink and t...\n",
       "2399    yelp       Service was good and the company was better!\n",
       "\n",
       "[2400 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data by pandas library\n",
    "import pandas as pd\n",
    "X_train = pd.read_csv('x_train.csv', header=None)\n",
    "y_train =pd.read_csv('y_train.csv', header=None)\n",
    "X_test = pd.read_csv('x_test.csv', header=None)\n",
    "y_test = pd.read_csv('y_test.csv', header=None)\n",
    "\n",
    "\n",
    "# check for null values\n",
    "null_values_X_train = X_train.isnull()\n",
    "null_values_y_train = y_train.isnull()\n",
    "null_values_X_test = X_test.isnull()\n",
    "null_values_y_test = y_test.isnull()\n",
    "print(null_values_X_train)\n",
    "print(null_values_y_train)\n",
    "print(null_values_X_test)\n",
    "print(null_values_y_test)\n",
    "\n",
    "# select rows that contain the substring '#NAME?' in any column of the X_train DataFrame\n",
    "X_train[X_train.apply(lambda row: row.astype(str).str.contains('#NAME?', na=False).any(), axis=1)]\n",
    "\n",
    "# select rows that contain the substring '#NAME?' in any column of the y_train DataFrame\n",
    "y_train[y_train.apply(lambda row: row.astype(str).str.contains('#NAME?', na=False).any(), axis=1)]\n",
    "\n",
    "# select rows that contain the substring '#NAME?' in any column of the X_test DataFrame\n",
    "X_test[X_test.apply(lambda row: row.astype(str).str.contains('#NAME?', na=False).any(), axis=1)]\n",
    "\n",
    "# select rows that contain the substring '#NAME?' in any column of the X_test DataFrame\n",
    "y_test[y_test.apply(lambda row: row.astype(str).str.contains('#NAME?', na=False).any(), axis=1)]\n",
    "\n",
    "# Merge the datasets horizontally\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3423bc",
   "metadata": {},
   "source": [
    "### Task 2 - Feature Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646b766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2858\n",
      "Feature matrix shape for train set: (2160, 2858)\n",
      "Feature matrix shape for test set: (600, 2858)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# download necessary stopwords and stemmer\n",
    "nltk.download(\"stopwords\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remove non-alphabetic characters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # correct spelling errors\n",
    "    text = str(TextBlob(text).correct())\n",
    "\n",
    "    # remove stopwords and perform stemming\n",
    "    words = text.split()\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# apply preprocess function on the second column\n",
    "X_train = X_train[1].apply(preprocess_text)\n",
    "X_test = X_test[1].apply(preprocess_text)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split X_train into a 90% training set and a 10% validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# define the bag-of-words feature representation\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "\n",
    "# fit the vectorizer to the datasets and transform the datasets\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# get the vocabulary size\n",
    "vocab_size = len(vectorizer.vocabulary_)\n",
    "\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "print(\"Feature matrix shape for train set:\", X_train.shape)\n",
    "print(\"Feature matrix shape for test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b02c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811aed4e",
   "metadata": {},
   "source": [
    "### Task 3 - Classification and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26cfc03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Validation: accuracy=0.775, precision=0.780, recall=0.780, f1_score=0.780\n",
      "Logistic Regression - Test: accuracy=0.787, precision=0.803, recall=0.760, f1_score=0.781\n",
      "\n",
      "Logistic Regression - validation confusion matrix:\n",
      "[[90 27]\n",
      " [27 96]]\n",
      "Logistic Regression - test Confusion matrix:\n",
      "[[244  56]\n",
      " [ 72 228]]\n",
      "Multinomial Naive Bayes - Validation: accuracy=0.804, precision=0.802, recall=0.821, f1_score=0.811\n",
      "Multinomial Naive Bayes - Test: accuracy=0.793, precision=0.788, recall=0.803, f1_score=0.795\n",
      "\n",
      "Multinomial Naive Bayes - validation confusion matrix:\n",
      "[[ 92  25]\n",
      " [ 22 101]]\n",
      "Multinomial Naive Bayes - test Confusion matrix:\n",
      "[[235  65]\n",
      " [ 59 241]]\n",
      "Support Vector Machine - Validation: accuracy=0.787, precision=0.840, recall=0.724, f1_score=0.777\n",
      "Support Vector Machine - Test: accuracy=0.758, precision=0.811, recall=0.673, f1_score=0.736\n",
      "\n",
      "Support Vector Machine - validation confusion matrix:\n",
      "[[100  17]\n",
      " [ 34  89]]\n",
      "Support Vector Machine - test Confusion matrix:\n",
      "[[253  47]\n",
      " [ 98 202]]\n",
      "Random Forest - Validation: accuracy=0.796, precision=0.843, recall=0.740, f1_score=0.788\n",
      "Random Forest - Test: accuracy=0.773, precision=0.847, recall=0.667, f1_score=0.746\n",
      "\n",
      "Random Forest - validation confusion matrix:\n",
      "[[100  17]\n",
      " [ 32  91]]\n",
      "Random Forest - test Confusion matrix:\n",
      "[[264  36]\n",
      " [100 200]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the models and their hyperparameters\n",
    "models = [{'name':'Logistic Regression', 'estimator': LogisticRegression(), 'hyperparameters':{'penalty': ['l1', 'l2'],\n",
    "            'C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    {   'name': 'Multinomial Naive Bayes',\n",
    "        'estimator': MultinomialNB(),\n",
    "        'hyperparameters': {\n",
    "            'alpha': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Support Vector Machine',\n",
    "        'estimator': SVC(),\n",
    "        'hyperparameters': {\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'estimator': RandomForestClassifier(),\n",
    "        'hyperparameters': {\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_depth': [None, 5, 10]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# hyperparameter tuning and evaluation\n",
    "cv_results = []\n",
    "for model in models:\n",
    "    grid = GridSearchCV(\n",
    "        estimator=model['estimator'], \n",
    "        param_grid=model['hyperparameters'], \n",
    "        cv=3, \n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    cv_results.append((model['name'], grid.best_params_, grid.best_score_))\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# evaluate the models on the validation and test sets\n",
    "for model in models:\n",
    "    i = models.index(model)\n",
    "    model['estimator'].set_params(**cv_results[i][1])\n",
    "    model['estimator'].fit(X_train, y_train)\n",
    "    y_pred_val = model['estimator'].predict(X_val)\n",
    "    y_pred_test = model['estimator'].predict(X_test)\n",
    "\n",
    "    # calculate evaluation metrics\n",
    "    # evaluation on valitation set\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    precision_val = precision_score(y_val, y_pred_val)\n",
    "    recall_val = recall_score(y_val, y_pred_val)\n",
    "    f1_val = f1_score(y_val, y_pred_val)\n",
    "    cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "\n",
    "    # evaluation on test set\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "    # print evaluation metrics\n",
    "    print(f\"{model['name']} - Validation: accuracy={accuracy_val:.3f}, precision={precision_val:.3f}, recall={recall_val:.3f}, f1_score={f1_val:.3f}\")\n",
    "    print(f\"{model['name']} - Test: accuracy={accuracy_test:.3f}, precision={precision_test:.3f}, recall={recall_test:.3f}, f1_score={f1_test:.3f}\\n\")\n",
    "    print(f\"{model['name']} - validation confusion matrix:\\n{cm_val}\")\n",
    "    print(f\"{model['name']} - test Confusion matrix:\\n{cm_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147233c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Logistic Regression', {'C': 1, 'penalty': 'l2'}, 0.7958333333333334),\n",
       " ('Multinomial Naive Bayes', {'alpha': 1}, 0.7916666666666666),\n",
       " ('Support Vector Machine',\n",
       "  {'C': 0.1, 'kernel': 'linear'},\n",
       "  0.7851851851851852),\n",
       " ('Random Forest',\n",
       "  {'max_depth': None, 'n_estimators': 100},\n",
       "  0.7754629629629629)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263403be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# define the classifier names and cross-validation results\n",
    "classifiers = ['Logistic Regression', 'Naive Bayes', 'Support Vector Machine', 'Random Forest']\n",
    "cv_results = [0.775, 0.804, 0.787, 0.792]\n",
    "\n",
    "# plot scores for Cross validation\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(classifiers, cv_results, align='center')\n",
    "ax.set_xlim(0.7, 0.85)\n",
    "ax.set_xlabel('Mean cross-validation score')\n",
    "ax.set_title('Classifier performance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15c754",
   "metadata": {},
   "source": [
    "### Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae5d3c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: 1\n"
     ]
    }
   ],
   "source": [
    "# select the best model\n",
    "best_model = MultinomialNB()\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# use the best model to predict the sentiment of a new sentence\n",
    "new_sentence = \"This movie was really great!\"\n",
    "new_sentence = preprocess_text(new_sentence)\n",
    "new_sentence_feature = vectorizer.transform([new_sentence]).toarray()\n",
    "sentiment = best_model.predict(new_sentence_feature)[0]\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199fef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "# select the best model\n",
    "best_model = MultinomialNB()\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# use the best model to predict the sentiment of a new sentence\n",
    "new_sentence = \"It always cuts out and makes a beep beep beep sound then says signal faild\"\n",
    "new_sentence = preprocess_text(new_sentence)\n",
    "new_sentence_feature = vectorizer.transform([new_sentence]).toarray()\n",
    "sentiment = best_model.predict(new_sentence_feature)[0]\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b86b59",
   "metadata": {},
   "source": [
    "#### Show representative examples of false positives and false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a141737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>amazon</td>\n",
       "      <td>W810i is just SUPERB.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Cheap but hey it works.. Was pleasantly supris...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>amazon</td>\n",
       "      <td>No shifting, no bubbling, no peeling, not even...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>amazon</td>\n",
       "      <td>The delivery was on time.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>amazon</td>\n",
       "      <td>The eargels channel the sound directly into yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The pizza selections are good.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>yelp</td>\n",
       "      <td>These are the nicest restaurant owners I've ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>yelp</td>\n",
       "      <td>First time going but I think I will quickly be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>yelp</td>\n",
       "      <td>My boyfriend and i sat at the bar and had a co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>yelp</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Source                                            Reviews  Sentiment  \\\n",
       "102  amazon                              W810i is just SUPERB.          1   \n",
       "104  amazon  Cheap but hey it works.. Was pleasantly supris...          1   \n",
       "108  amazon  No shifting, no bubbling, no peeling, not even...          1   \n",
       "111  amazon                          The delivery was on time.          1   \n",
       "113  amazon  The eargels channel the sound directly into yo...          1   \n",
       "..      ...                                                ...        ...   \n",
       "586    yelp                     The pizza selections are good.          1   \n",
       "589    yelp  These are the nicest restaurant owners I've ev...          1   \n",
       "590    yelp  First time going but I think I will quickly be...          1   \n",
       "591    yelp  My boyfriend and i sat at the bar and had a co...          1   \n",
       "596    yelp                                             #NAME?          1   \n",
       "\n",
       "     Prediction  \n",
       "102           0  \n",
       "104           0  \n",
       "108           0  \n",
       "111           0  \n",
       "113           0  \n",
       "..          ...  \n",
       "586           0  \n",
       "589           0  \n",
       "590           0  \n",
       "591           0  \n",
       "596           0  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert y-pred-test to dataframe\n",
    "y_pred_test = pd.DataFrame(y_pred_test, columns=['Prediction'])\n",
    "y_pred_test\n",
    "\n",
    "# add column names\n",
    "test_data.columns = ['Source', 'Reviews', 'Sentiment']\n",
    "\n",
    "# concatenate the X_train DataFrame with the y_train_pred DataFrame\n",
    "Comparison_data = pd.concat([test_data, y_pred_test], axis=1)\n",
    "Comparison_data\n",
    "\n",
    "# identify false positives and false negatives\n",
    "false_positives = Comparison_data[(Comparison_data['Sentiment']==0) & (Comparison_data['Prediction']==1)]\n",
    "false_positives\n",
    "false_negatives = Comparison_data[(Comparison_data['Sentiment']==1) & (Comparison_data['Prediction']==0)]\n",
    "false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de5f2f",
   "metadata": {},
   "source": [
    "#### Does it do better on longer sentences or shorter sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eab6d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    12.227941\n",
      "True     11.549569\n",
      "Name: num_words, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# count the number of words in each cell of the 'text' column\n",
    "Comparison_data['num_words'] = Comparison_data['Reviews'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# group the data by the condition \"if the prediction matches the sentiment (label)\"\n",
    "grouped = Comparison_data.groupby(Comparison_data['Sentiment'] == Comparison_data['Prediction'])\n",
    "\n",
    "# calculate the average number of words in the reviews for each group\n",
    "avg_num_words = grouped['num_words'].mean()\n",
    "\n",
    "# print the results\n",
    "print(avg_num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1faabe",
   "metadata": {},
   "source": [
    "#### Does it do better on a particular kind of review (amazon or imdb)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d653a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source\n",
       "amazon    75\n",
       "imdb      59\n",
       "yelp      66\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred_source = Comparison_data[Comparison_data['Prediction'] == Comparison_data['Sentiment']].groupby('Source').sum()['Prediction']\n",
    "correct_pred_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3f5cc",
   "metadata": {},
   "source": [
    "#### Does it do better on sentences without negation words (\"not\", \"didn't\", \"shouldn't\", etc.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be9f76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_negation\n",
       "False    184\n",
       "True      16\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to check if a sentence contains negation words\n",
    "def has_negation(sentence):\n",
    "    negation_words = ['not', 'never', 'didn\\'t', 'couldn\\'t', 'wouldn\\'t', 'shouldn\\'t', 'don\\'t', 'won\\'t']\n",
    "    for word in negation_words:\n",
    "        if word in sentence:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Create a new column to indicate if each sentence has negation words or not\n",
    "Comparison_data['has_negation'] = Comparison_data['Reviews'].apply(has_negation)\n",
    "\n",
    "correct_pred_negation = Comparison_data[Comparison_data['Prediction'] == Comparison_data['Sentiment']].groupby('has_negation').sum()['Prediction']\n",
    "correct_pred_negation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
